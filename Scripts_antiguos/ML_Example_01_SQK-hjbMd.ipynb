{"cells": [{"metadata": {}, "cell_type": "code", "source": "from random import randint\nimport time\nfrom sklearn.linear_model import LinearRegression\n", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "TRAIN_SET_LIMIT = 1000\nTRAIN_SET_COUNT = 1000000\n\nTRAIN_INPUT = list()\nTRAIN_OUTPUT = list()\nfor i in range(TRAIN_SET_COUNT):\n    a = randint(0, TRAIN_SET_LIMIT)\n    b = randint(0, TRAIN_SET_LIMIT)\n    c = randint(0, TRAIN_SET_LIMIT)\n    op = a + (2*b) + (3*c)\n    TRAIN_INPUT.append([a, b, c])\n    TRAIN_OUTPUT.append(op)", "execution_count": 37, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predictor = LinearRegression(n_jobs=-1)", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "start = time.time()\npredictor.fit(X=TRAIN_INPUT, y=TRAIN_OUTPUT)\nend = time.time()\nprint(end - start)", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "0.743401288986206\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "X_TEST = [[10, 20, 30]]\noutcome = predictor.predict(X=X_TEST)\ncoefficients = predictor.coef_\n", "execution_count": 40, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('Outcome : {}\\nCoefficients : {}'.format(outcome, coefficients))", "execution_count": 41, "outputs": [{"output_type": "stream", "text": "Outcome : [140.]\nCoefficients : [1. 2. 3.]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import pyspark", "execution_count": 42, "outputs": [{"output_type": "error", "ename": "ModuleNotFoundError", "evalue": "No module named 'pyspark'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m<ipython-input-42-49d7c4e178f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}