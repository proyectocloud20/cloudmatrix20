{"cells": [{"metadata": {}, "cell_type": "code", "source": "%%writefile spatial_functions.py", "execution_count": null, "outputs": []}, {"metadata": {"collapsed": true}, "cell_type": "code", "source": "import gdal, ogr, osr\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport shapely as shp\nimport os\nfrom rsgislib.segmentation import segutils\nfrom rsgislib import vectorutils\nimport rasterstats\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nimport richdem\nimport psycopg2\nfrom rpy2.robjects.packages import importr\nfrom rpy2 import robjects\nfrom rpy2.robjects.vectors import StrVector\nimport rpy2.robjects.packages as rpackages\n\ndef create_folders(tmp):\n    \"\"\"\n    :param tmp: temporal folder where the different and need folders will be created\n    :return: dictionary with name of the folder and path\n    \"\"\"\n\n    dict_paths = {\n        \"LiDAR_subset\" : f\"{tmp}/LiDAR_subset\",\n        \"layers\" : f\"{tmp}/layers\",\n        \"images\" : f\"{tmp}/images\",\n        \"crop_images\" : f\"{tmp}/image_tiles/crop_images\",\n        \"crop_means\" : f\"{tmp}/image_tiles/crop_means\",\n        \"crop_stacks\" : f\"{tmp}/image_tiles/crop_stacks\",\n        \"lidar_tifs\" : f\"{tmp}/image_tiles/lidar_tifs\",\n        \"las_tiles\" : f\"{tmp}/las_tiles\",\n        \"seg_crop\" : f\"{tmp}/image_tiles/seg_crop\",\n        \"segemented_tiles\" : f\"{tmp}/image_tiles/segmented_tiles\",\n        \"crop_stackForStats\" : f\"{tmp}/image_tiles/crop_stackForstats\",\n        \"segmented_stats\" : f\"{tmp}/image_tiles/segmented_stats\",\n        \"tile_prediction\" : f\"{tmp}/image_tiles/tile_prediction\",\n        \"forest_fuel\" : f\"{tmp}/image_tiles/forest_fuel\",\n        \"T_tiles\" : f\"{tmp}/image_tiles/temp_tiles\",\n        \"H_tiles\" : f\"{tmp}/image_tiles/reH_tiles\",\n        \"PIG_tiles\" : f\"{tmp}/image_tiles/pig_tiles\",\n        \"fireRisk\" : f\"{tmp}/image_tiles/fireRisk\"\n    }\n\n    out = list(map(lambda x: os.makedirs(x[1], exist_ok = True), dict_paths.items()))\n    return(dict_paths)\n\ndef get_layerextent(layer_path):\n    \"\"\"\n    Return the extent of layer with GPKG or ESRI Shapefile formats\n    :param layer_path: Path to the layer\n    :return: String with xmin, ymin, xmax and ymax coordinates.\n    \"\"\"\n    longitud = len(layer_path.split(\".\"))\n    driver_name = layer_path.split(\".\")[longitud - 1]\n    if driver_name == \"gpkg\":\n        driver = ogr.GetDriverByName(\"GPKG\")\n    if driver_name == \"shp\":\n        driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n\n    ds = driver.Open(layer_path)\n    xmin, xmax, ymin, ymax = ds.GetLayer().GetExtent()\n    extent = f\"{xmin}, {ymin}, {xmax}, {ymax}\"\n\n    del ds\n\n    return (extent)\n\n\n\ndef get_rasterextent(raster, dictionary = False):\n    \"\"\"\n    Get the extent of a raster image\n    :param raster: Path to the raster file\n    :param dictionary: If True, a dictionary with the path of the raster as key and the extent of the raster as value is returned.\n    :return: The extent with next order: xmin, xmax, ymin and ymax coordinates\n    \"\"\"\n\n    r = gdal.Open(raster)\n    ulx, xres, xskew, uly, yskew, yres = r.GetGeoTransform()\n    lrx = ulx + (r.RasterXSize * xres)\n    rly = uly + (r.RasterYSize * yres)\n\n    # xmin, xmax, ymin and ymax\n    extent = [ulx, lrx, rly, uly]\n    if dictionary:\n        return({raster: extent})\n    else:\n        return (extent)\n\n\ndef createGrid(path_to_layer, spacing = 10000, epsg = 25830, buffer = None, output=None):\n    \"\"\"\n    Creates a grid from a layer extent.\n    :param path_to_layer: Path to layer\n    :param spacing: Spacing of the grid cells (it applies to x and y)\n    :param epsg: EPSG code of the coordinate\n    :param buffer: Buffer to apply to the extent coordinates\n    :param output: If defined, it creates an output.\n    :return: Grid in geopandas format\n    \"\"\"\n\n    gdf = gpd.read_file(path_to_layer)\n    xmin, ymin, xmax, ymax = gdf.total_bounds\n\n    # To be sure the bounding box created has all the set of points inside and it is multiple of the spacing.\n\n    ytop = np.ceil(np.ceil(ymax) / spacing) * spacing\n    ybottom = np.floor(np.floor(ymin) / spacing) * spacing\n    xright = np.ceil(np.ceil(xmax) / spacing) * spacing\n    xleft = np.floor(np.floor(xmin) / spacing) * spacing\n\n    # Defining number of rows and columns\n    rows = int((ytop - ybottom) / spacing)\n    cols = int((xright - xleft) / spacing)\n\n    polygons = []\n    it = 0\n    listfid = []\n    for i in np.arange(xleft, xright, spacing):\n        xleft = i\n        xright = xleft + spacing\n        ytop_backup = ytop\n        for j in np.arange(ytop, ybottom, -spacing):\n            ytop = j\n            ybottom = ytop - spacing\n\n            polygon = shp.geometry.Polygon([\n                (xleft, ytop),\n                (xright, ytop),\n                (xright, ybottom),\n                (xleft, ybottom)\n            ]\n            )\n            polygons.append(polygon)\n            listfid.append(it)\n            it += 1\n        ytop = ytop_backup\n        # print(f\"xleft: {xleft} xright: {xright} \\n ytop: {ytop} ybottom: {ybottom}\")\n\n    # print(polygons)\n    srs = f\"epsg:{epsg}\"\n    fid = pd.DataFrame({\"fid_id\": listfid})\n    grid = gpd.GeoDataFrame(fid, geometry=polygons, crs={\"init\": srs})\n\n    if output is not None:\n        print(\"Writing grid into disk\")\n        grid.to_file(output, driver=\"GPKG\")\n\n    #################################################\n    ## BETTER TO RETURN JUST INTERSECTING POLYGONS ##\n    #################################################\n    if buffer:\n        buf = grid.geometry.buffer(buffer)\n        envelope = buf.envelope\n        return(envelope)\n    else:\n        return(grid)\n\n\ndef reproject(image, output_folder, epsg_to=3035, return_output_path = False):\n    \"\"\"\n    This function reprojects a raster image\n\n    :param image: path to raster image\n    :param output_folder: output folder where the output image will be saved\n    :param epsg_to: coordinate epsg code to reproject into\n    :param return_output_path: If True, it returns the output path\n    :return: returns a virtual data source\n    \"\"\"\n    splitted = image.split(\"/\")\n    lenout = len(splitted)\n    out_name = splitted[lenout-1]\n    output = f\"{output_folder}/reprojeted_{out_name}\"\n\n    dataset = gdal.Open(image)\n    srs = osr.SpatialReference()\n    srs.ImportFromEPSG(epsg_to)\n    vrt_ds = gdal.AutoCreateWarpedVRT(dataset, None, srs.ExportToWkt(), gdal.GRA_NearestNeighbour)\n\n    # cols = vrt_ds.RasterXSize\n    # rows = vrt_ds.RasterYSize\n    gdal.GetDriverByName(\"GTiff\").CreateCopy(output, vrt_ds)\n\n    if return_output_path:\n        return(output)\n    else:\n        return(vrt_ds)\n\n\n# def masking_tiles(layer_tiles, raster_path, output_folder, field=\"fid_id\"):\n#     if os.path.exists(output_folder) is False:\n#         os.mkdir(output_folder)\n#\n#     driver = ogr.GetDriverByName(\"GPKG\")\n#     ds = driver.Open(layer_tiles)\n#     layer = ds.GetLayer()\n#     for feature in layer:\n#         geom = feature.geometry()\n#         fid = feature.GetField(field)\n#         out_name = naming_convention(raster_path, geom)\n#         # print(out_name)\n#         output = f\"{output_folder}/{out_name}.tif\"\n#\n#\n#         ds2 = gdal.Warp(output,\n#                         raster_path,\n#                         format=\"GTiff\",\n#                         cutlineDSName=layer_tiles,\n#                         cutlineWhere=f\"{field} == '{fid}'\",\n#                         cropToCutline=True)\n#     layer.ResetReading()\n#     ds.FlushCache()\n#     del ds2\n#     del ds\n\ndef masking_tiles(layer_tiles,\n                  raster_path,\n                  output_folder,\n                  field=\"fid_id\",\n                  naming=False,\n                  extent=False,\n                  lesser_lextent=False,\n                  reproyectar=False,\n                  epsg=25830\n                  ):\n    \"\"\"\n    It creates tiles from a raster image based on a grid previously created\n    :param layer_tiles: Path to grid\n    :param raster_path: Path to raster\n    :param output_folder: Path to output folder\n    :param field: Field with cut tiles with\n    :param naming: Apply naming rule\n    :param extent: Cut with extent\n    :param lesser_lextent: create an smaller extent\n    :param reproyectar: If True, reprojection is applied\n    :param epsg: EPSG code of the srs to reproject into\n    :return:\n    \"\"\"\n    if os.path.exists(output_folder) is False:\n        os.mkdir(output_folder)\n\n    if reproyectar:\n        raster_path2 = raster_path\n        raster_path = reproject(raster_path, \"/tmp\", epsg_to=epsg, return_output_path=True)\n        print(raster_path)\n\n    driver = ogr.GetDriverByName(\"GPKG\")\n    ds = driver.Open(layer_tiles)\n    layer = ds.GetLayer()\n    for feature in layer:\n        geom = feature.geometry()\n        fid = feature.GetField(field)\n        if naming:\n            if reproyectar:\n                out_name = naming_convention(raster_path2, geom)\n            else:\n                out_name = naming_convention(raster_path, geom)\n        else:\n            out_tmp = raster_path.split(\"/\")\n            out_tmp2 = out_tmp[len(out_tmp) - 1]\n            out_name = out_tmp2.split(\".\")[0]\n\n        output = f\"{output_folder}/{out_name}.tif\"\n\n        if extent:\n            raster_extent = get_rasterextent(raster_path)\n            sepuede = layer_within_raster(raster_extent, geom, lesser_lextent=lesser_lextent)\n\n            if sepuede:\n                xmin, xmax, ymin, ymax = geom.GetEnvelope()\n                lextent = [xmin, ymin, xmax, ymax]\n\n                ds2 = gdal.Warp(output,\n                                raster_path,\n                                format=\"GTiff\",\n                                outputBounds=lextent)\n\n                del ds2\n\n        else:\n            ds2 = gdal.Warp(output,\n                            raster_path,\n                            format=\"GTiff\",\n                            cutlineDSName=layer_tiles,\n                            cutlineWhere=f\"{field} = '{fid}'\",\n                            cropToCutline=True)\n            del ds2\n\n    layer.ResetReading()\n    ds.FlushCache()\n\n    del ds\n\n\n\ndef mask_all_images(folder_images, layer_tiles, output_folder, field = \"fid_id\", lesser_lextent = False, reproyectar = False, naming = False, bandas = [\"B02\", \"B03\", \"B04\", \"B08\"]):\n    \"\"\"\n    Iterate through Sentinel .SAFE format looking for images and mask them with masking_tiles function\n\n    :param folder_images: .SAFE folder\n    :param layer_tiles: Path to grid\n    :param output_folder: Folder where save outputs\n    :param field:  Field to cut with\n    :param lesser_lextent: For cutting with a smaller exent\n    :param reproyectar: If a apply a reprojection\n    :param naming: If apply a naming rule\n    :param bandas: list of bands selected bands\n    :return:\n    \"\"\"\n    for folder in os.listdir(folder_images):\n        if \".zip\" not in folder:\n            newfolder = f\"{folder_images}/{folder}\"\n            for folder2 in os.listdir(newfolder):\n                if \"GRANULE\" in folder2:\n                    newnewfolder = f\"{newfolder}/{folder2}\"\n                    for folder3 in os.listdir(newnewfolder):\n                        newnewnewfolder = f\"{newnewfolder}/{folder3}\"\n                        for img_data in os.listdir(newnewnewfolder):\n                            if \"IMG_DATA\" in img_data:\n                                newnewnewnewfolder = f\"{newnewnewfolder}/{img_data}\"\n                                for image in os.listdir(newnewnewnewfolder):\n                                    if image.endswith(\".jp2\"):\n\n                                        # Subsetting bands\n                                        tmp = image.split(\".\")[0]\n                                        tile, date, band = tmp.split(\"_\")\n                                        if band in bandas:\n                                            path_image = f\"{newnewnewnewfolder}/{image}\"\n                                            print(path_image)\n                                            masking_tiles(layer_tiles = layer_tiles,\n                                                          raster_path = path_image,\n                                                          output_folder = output_folder,\n                                                          field = field,\n                                                          reproyectar = reproyectar,\n                                                          naming = naming,\n                                                          lesser_lextent = lesser_lextent)\n\n\ndef mask_lidarImages_folder(tiles_folder, variable, field=\"fid_id\", tile_spacing = 250, lesser_lextent = False):\n    \"\"\"\n    Mask out the buffers of rasters created with LiDAR tiles.\n\n    :param tiles_folder: Folder with the different tiles\n    :param variable: Variable to mask out\n    :param field: Field of the grid to cut buffers out\n    :param tile_spacing: Spacing of the tile\n    :param lesser_lextent: If it will use a smaller extent or not.\n    :return:\n    \"\"\"\n\n    for folder in os.listdir(tiles_folder):\n        print(folder)\n        newfolder = f\"{tiles_folder}/{folder}\"  # Coordinates folder\n        layer_tiles = f\"{newfolder}/{folder}_tiles_{tile_spacing}m.gpkg\"\n        #         print(layer_tiles)\n        if os.path.isdir(newfolder):\n            for folder2 in os.listdir(newfolder):\n\n                # DEM folder\n                newnewfolder = f\"{newfolder}/{folder2}\"\n                if folder2 == variable:\n\n                    # images inside folder\n                    for image in os.listdir(newnewfolder):\n                        if os.path.isdir(f\"{newnewfolder}/{image}\") is False:\n                            path_image = f\"{newnewfolder}/{image}\"\n                            output = f\"{newnewfolder}/mask\"\n\n                            masking_tiles(layer_tiles=layer_tiles,\n                                          raster_path=path_image,\n                                          output_folder=output,\n                                          field=field, extent=True, lesser_lextent = lesser_lextent)\n\n\ndef create_raster(in_ds, fn, data, data_type, nodata=None, driver=\"GTiff\", band_names=None):\n    \"\"\"\n    Based on Geoprocessing with python.\n    Create a one-band GeoTiff\n\n    in_ds         - datasource to copy projection and geotransform from\n    fn            - path to the file to create\n    data          - NumPy array containing data to write\n    data_type     - output data type\n    nodata        - optional NoData value\n    band_names    - optional. It gives a name to each band for easier identification. It has to have same length than data dimensions.\n    \"\"\"\n\n    driver = gdal.GetDriverByName(driver)\n    #     print(band_names)\n    # Creating out raster framework\n    columns = in_ds.RasterXSize\n    rows = in_ds.RasterYSize\n    try:\n        nbands = int(data.shape[2])\n    except:\n        nbands = 1\n    out_ds = driver.Create(fn, columns, rows, nbands, data_type)\n\n    # Assigning out raster projection and geotransform\n    out_ds.SetProjection(in_ds.GetProjection())\n    out_ds.SetGeoTransform(in_ds.GetGeoTransform())\n\n    # Iterate through bands if necessary\n    if nbands > 1:\n        for k in range(0, nbands):\n            out_band = out_ds.GetRasterBand(k + 1)\n            if nodata is not None:\n                out_band.SetNoDataValue(nodata)\n            out_band.WriteArray(data[:, :, k])\n\n            if band_names is not None:\n                out_band.SetDescription(band_names[k])\n                metadata = out_band.GetMetadata()\n                metadata = f\"TIFFTAG_IMAGEDESCRIPTION={band_names[k]}\"\n                out_band.SetMetadata(metadata)\n\n    else:\n        out_band = out_ds.GetRasterBand(1)\n        if nodata is not None:\n            out_band.SetNoDataValue(nodata)\n\n        out_band.WriteArray(data)\n    #         print(out_band.ReadAsArray())\n\n    out_band.FlushCache()\n    out_band.ComputeStatistics(False)\n    del out_ds\n\n\ndef temporal_band_means(path, out_path, bandas=[\"B02\", \"B03\", \"B04\", \"B08\"]):\n    \"\"\"\n    Create temporal band means from tiles base on their names\n\n    :param path: Path to folder with image tiles\n    :param out_path: path to output folder\n    :param bandas: band to be considered\n    :return:\n    \"\"\"\n    def get_array(file):\n        path_to_file = f\"{path}/{file}\"\n        ds = gdal.Open(path_to_file)\n        arr = ds.GetRasterBand(1).ReadAsArray()\n        return (arr)\n        del ds\n\n    def get_band_names(name):\n        band = name[31:34]\n        out = f\"{band}\"\n        return (out)\n\n    date = []\n    coordinates = []\n    band = []\n    tile = []\n\n    listfiles = os.listdir(path)\n    for file in listfiles:\n        date.append(file[:8])\n        coordinates.append(file[9:27])\n        band.append(file[35:38])\n        tile.append(file[28:34])\n\n    date = set(date)\n    coordinates = set(coordinates)\n    band = set(band)\n    tile = set(tile)\n\n\n\n    # Grouping by tile\n    for t in tile:\n        tmp1 = list(filter(lambda x: x[28:34] == t, listfiles))\n\n        #         print(tmp1)\n        for c in coordinates:\n            # getting files based on coordinates\n            tmp2 = list(filter(lambda x: x[9:27] == c, tmp1))\n            tmp2.sort()\n            #             print(tmp2)\n            lista_means = []\n            bnames = []\n            for b in band:\n                if b in bandas:\n                    list_bandas = list(filter(lambda x: x[35:38] == b, tmp2))\n                    #                     bnames = list(map(lambda x: get_band_names(x), list_bandas))\n                    arrays = list(map(get_array, list_bandas))\n                    forstack = np.stack(arrays, axis=2)\n                    lista_means.append(np.mean(forstack, axis=2))\n                    bnames.append(b)\n\n            #             print(bnames)\n            # Stacking band means on a array\n            stack_mean = np.stack(lista_means, axis=2)\n            pathds = f\"{path}/{list_bandas[0]}\"\n            ds_tmp = gdal.Open(pathds)\n            create_raster(in_ds=ds_tmp, fn=f\"{out_path}/tbandMean_{list_bandas[0][9:34]}.tif\",\n                          data=stack_mean, data_type=gdal.GDT_Float32, band_names=bnames)\n\n\ndef tile_temporal_stack(path, out_path, bandas=[\"B02\", \"B03\", \"B04\", \"B08\"]):\n    \"\"\"\n    Create a temporal stack of the bands selected\n    :param path: Path to folder with image tiles\n    :param out_path: path to output folder\n    :param bandas: band to be considered\n    :return:\n    \"\"\"\n    def get_array(file):\n        path_to_file = f\"{path}/{file}\"\n        ds = gdal.Open(path_to_file)\n        arr = ds.GetRasterBand(1).ReadAsArray()\n        return (arr)\n        del ds\n\n    def get_band_names(name):\n        date = name[:8]\n        band = name[35:38]\n        out = f\"{date}_{band}\"\n        return (out)\n\n    # Saving date, coordinates and band of tiles\n    date = []\n    coordinates = []\n    band = []\n    tile = []\n    listfiles = os.listdir(path)\n    for file in listfiles:\n        date.append(file[:8])\n        coordinates.append(file[9:27])\n        band.append(file[35:38])\n        tile.append(file[28:34])\n\n    date = set(date)\n    coordinates = set(coordinates)\n    band = set(band)\n    tile = set(tile)\n\n    # getting all date and bands for each tile\n    for t in tile:\n        tmp1 = list(filter(lambda x: x[28:34] == t, listfiles))\n        tmp2 = list(filter(lambda x: x[35:38] in bandas, tmp1))\n        for c in coordinates:\n            tmp3 = list(filter(lambda x: x[9:27] == c, tmp2))\n            tmp3.sort()\n            bnames = list(map(lambda x: get_band_names(x), tmp3))\n\n            # Getting arrays and stacking arrays\n            arrays = list(map(get_array, tmp3))\n            data = np.stack(arrays, axis=2)\n\n            # saving out\n            pathds = f\"{path}/{tmp3[0]}\"\n            ds_tmp = gdal.Open(pathds)\n            create_raster(in_ds=ds_tmp, fn=f\"{out_path}/tStack_{tmp3[0][9:34]}.tif\",\n                          data=data, data_type=gdal.GDT_Float32, band_names=bnames)\n\ndef create_grid_from_name(folder_with_tiles, spacing = 500, intile_length = 1000, epsg = 25830):\n    \"\"\"\n    Creates a grid based on the name of the folders\n    :param folder_with_tiles: path to folder with tiles\n    :param spacing: Spacing of the desired grid cells\n    :param intile_length: an smallers spacing to be considered\n    :param epsg: EPSG code to define projection\n    :return:\n    \"\"\"\n    for folder in os.listdir(folder_with_tiles):\n        xmin, ymax = folder.split(\"-\")\n        xmax = float(xmin) + intile_length\n        ymin = float(ymax) - intile_length\n\n        ytop = float(ymax)\n        ybottom = ymin\n        xleft = float(xmin)\n        xright = xmax\n\n        # Defining number of rows and columns\n        rows = int((ytop - ybottom) / spacing)\n        cols = int((xright - xleft) / spacing)\n\n        polygons = []\n        it = 0\n        listfid = []\n        for i in np.arange(xleft, xright, spacing):\n            xleft = i\n            xright = xleft + spacing\n            ytop_backup = ytop\n            for j in np.arange(ytop, ybottom, -spacing):\n                ytop = j\n                ybottom = ytop - spacing\n\n                polygon = shp.geometry.Polygon([\n                    (xleft, ytop),\n                    (xright, ytop),\n                    (xright, ybottom),\n                    (xleft, ybottom)\n                ]\n                )\n                polygons.append(polygon)\n                listfid.append(it)\n                it += 1\n            ytop = ytop_backup\n            # print(f\"xleft: {xleft} xright: {xright} \\n ytop: {ytop} ybottom: {ybottom}\")\n\n        # print(polygons)\n        srs = f\"epsg:{epsg}\"\n        fid = pd.DataFrame({\"fid_id\": listfid})\n        grid = gpd.GeoDataFrame(fid, geometry=polygons, crs={\"init\": srs})\n\n        print(\"Writing grid into disk\")\n        output = f\"{folder_with_tiles}/{folder}/{folder}_tiles_{spacing}m.gpkg\"\n\n        if os.path.exists(output):\n            os.remove(output)\n        grid.to_file(output, driver=\"GPKG\")\n\ndef naming_convention(raster_path, geometry):\n    \"\"\"\n    Creates naming based on the raster name and geometries: date_xmin-ymax_sentineltile_band\n    :param raster_path: Path to raster file\n    :param geometry: geom\n    :return:\n    \"\"\"\n    # xmin, xmax, ymin, ymax\n    xmin, xmax, ymin, ymax = geometry.GetEnvelope()\n    splitted = raster_path.split(\"/\")\n    len_splitted = len(splitted)\n    name_tmp1 = splitted[len_splitted - 1]\n    name = name_tmp1.split(\".\")[0]\n    name_splitted = name.split(\"_\")\n    if len(name_splitted) < 3:\n        outaname = f\"{name}_{float(xmin)}-{float(ymax)}\"\n    else:\n        sent_tile = name_splitted[0]\n        band = name_splitted[2]\n        date_tmp = name_splitted[1]\n        date = date_tmp.split(\"T\")[0]\n\n        # outaname = f\"{date}_{int(xmin)}_{int(ymax)}_{sent_tile}_{band}\"\n        outaname = f\"{date}_{float(xmin)}-{float(ymax)}_{sent_tile}_{band}\"\n    return (outaname)\n\n\ndef layer_within_raster(raster_extent, layer_geom, lesser_lextent=False):\n    \"\"\"\n    check if a layer is inside the raster\n    :param raster_extent: extent of the raster\n    :param layer_geom: layer geom\n    :param lesser_lextent: If True a smaller extent is evaluated\n    :return:\n    \"\"\"\n    rxmin, rxmax, rymin, rymax = raster_extent\n    lxmin, lxmax, lymin, lymax = layer_geom.GetEnvelope()\n\n    if lesser_lextent:\n        # Getting a smaller bounding box\n        lxmin = lxmin + 100\n        lxmax = lxmax - 100\n        lymin = lymin + 100\n        lymax = lymax - 100\n\n    i = 0\n    if lxmin >= rxmin:  # 1. upper left corner\n        i += 1\n    if lymax <= rymax:  # 2. upper right corner\n        i += 1\n    if lxmax <= rxmax:  # 3. lower right corner\n        i += 1\n    if lymin >= rymin:  # 4. lower left corner\n        i += 1\n\n    if i == 4:\n        out = True\n    else:\n        out = False\n    return (out)\n\n\ndef upto_ImageTile(ImageTiles_layer, rasterTiles_folder, output_folder, res=10, variable=\"DEM\"):\n    \"\"\"\n    Mosaic LiDAR images up to the image tiles spacing\n\n    :param ImageTiles_layer: Grid created for tile Sentinel images\n    :param rasterTiles_folder: LiDAR raster tiles\n    :param output_folder: Path to output folder\n    :param res: resolution desired for resampling)\n    :param variable: Variable to be mosaiced\n    :return:\n    \"\"\"\n    def list_right_rasters(folders_inside, previous_path, variable=variable):\n        if len(folders_inside) > 0:\n            folder = list(folders_inside.keys())[0]\n            after_path = f\"{variable}/mask\"\n            final_path = f\"{previous_path}/{folder}/{after_path}\"\n\n            listfiles = list(map(lambda x: x.path, os.scandir(final_path)))\n        print(listfiles)\n        return (listfiles)\n\n    def layer_within_folderExtent(folder, layer_geom, spacing=2000):\n        rxmin, rymax = list(map(lambda x: float(x), folder))\n        folder_name = f\"{folder[0]}-{folder[1]}\"\n        rxmax = rxmin + spacing\n        rymin = rymax - spacing\n        lxmin, lxmax, lymin, lymax = layer_geom.GetEnvelope()\n\n        i = 0\n        if lxmin >= rxmin:  # 1. upper left corner\n            i += 1\n        if lymax <= rymax:  # 2. upper right corner\n            i += 1\n        if lxmax <= rxmax:  # 3. lower right corner\n            i += 1\n        if lymin >= rymin:  # 4. lower left corner\n            i += 1\n\n        if i == 4:\n            out = {folder_name: True}\n        else:\n            out = {folder_name: False}\n\n        #     print(lxmin, lxmax, lymin, lymax)\n\n        #     print(layer_geom.GetEnvelope())\n        return (out)\n\n\n\n    tiles_folder = rasterTiles_folder\n    layer_path = ImageTiles_layer\n    output_variable = f\"{output_folder}/{variable}\"\n\n    if os.path.exists(output_variable) is False:\n        os.makedirs(output_variable, exist_ok = True)\n\n    ds = ogr.Open(layer_path)\n    layer = ds.GetLayer()\n    vrt_options = gdal.BuildVRTOptions(resampleAlg=\"nearest\", addAlpha=False, xRes=res, yRes=res)\n\n    folders = os.listdir(tiles_folder)\n    # path_folders = list(map(lambda x: f\"{tiles_folder}/{x}\", folders))\n\n    folders_xy = list(map(lambda x: [x.split(\"-\")[0], x.split(\"-\")[1]], folders))\n    # print(path_folders)\n\n    for feature in layer:\n        geom = feature.GetGeometryRef()\n        lxmin, lxmax, lymin, lymax = geom.GetEnvelope()\n\n\n        is_it_inside = list(map(layer_within_folderExtent, folders_xy, [geom] * len(folders_xy)))\n        wecan = list(filter(lambda x: list(x.values())[0] is True, is_it_inside))\n        # print(wecan)\n        listoflists = list(map(list_right_rasters, wecan, [rasterTiles_folder]*len(wecan)))\n        finallist = sum(listoflists, [])\n\n        if len(finallist) > 0:\n            dsvrt = gdal.BuildVRT(f\"{output_variable}/a_tmp.vrt\", finallist, options=vrt_options)\n            dsvrt.ReadAsArray()\n            dstif = gdal.Translate(f\"{output_variable}/{variable}_{lxmin}-{lymax}.tif\", dsvrt)\n            del dsvrt\n            del dstif\n\n            os.remove(f\"{output_variable}/a_tmp.vrt\")\n\n    del ds\n\n\ndef tiles_for_segmentation(crop_means, path_dsms, output):\n    \"\"\"\n    Prepare the stacks for segmentation\n    :param crop_means: Desire means stack\n    :param path_dsms: DSM raster files folder\n    :param output: output\n    :return:\n    \"\"\"\n    def get_band_name(band):\n        option_name = \"TIFFTAG_IMAGEDESCRIPTION\"\n        md = band.GetMetadata()\n        for k, v in md.items():\n            if k == option_name:\n                return (v)\n\n    def same_coordinates(a, b):\n        avariable, acoordinates, atile = a.split(\"_\")\n        bvariable, bcoordinates = b.split(\"_\")\n        bcoordinates = bcoordinates.split(\".tif\")[0]\n        #     print({acoordinates : bcoordinates})\n        if acoordinates == bcoordinates:\n            return (True)\n        else:\n            return (False)\n\n    lista_crops = os.listdir(crop_means)\n    lista_dsm = os.listdir(path_dsms)\n\n    crop_means_paths = list(map(lambda x: f\"{crop_means}/{x}\", lista_crops))\n    for crop in crop_means_paths:\n\n        for dsm in lista_dsm:\n            crop_tmp = crop.split(\"/\")\n            crop_tmp2 = crop_tmp[len(crop_tmp) - 1]\n            #         print(crop_tmp2)\n            if same_coordinates(crop_tmp2, dsm):\n                #             print(crop_tmp2)\n                ds = gdal.Open(crop)\n                count = ds.RasterCount\n                diccionario = {}\n\n                for bandi in range(1, count + 1):\n                    band = ds.GetRasterBand(bandi)\n                    band_name = get_band_name(band)\n                    arr = band.ReadAsArray()\n                    diccionario[band_name] = arr\n\n                path_dsm = f\"{path_dsms}/{dsm}\"\n                ds_dsm = gdal.Open(path_dsm)\n                dsm_band = ds_dsm.GetRasterBand(1)\n                arr_dsm = dsm_band.ReadAsArray()\n                diccionario[\"DSM\"] = arr_dsm\n\n                bands_list = []\n                arrays_list = []\n                for k, v in diccionario.items():\n                    bands_list.append(k)\n                    arrays_list.append(v)\n\n                array_stacked = np.stack(arrays_list, axis=2)\n                out_path = f\"{output}/SegCrop_{crop_tmp2[10:]}\"\n\n                create_raster(in_ds=ds,\n                              fn=out_path,\n                              data=array_stacked,\n                              data_type=gdal.GDT_Float32,\n                              band_names=bands_list\n                              )\n\n        ds = None\n        ds_dsm = None\n\n\ndef segmenta(entrada, salida=\"resultado.shp\",minPxls=100,distThres=100):\n    '''\n    Realiza la segmentaci\u00f3n del archivo que se pasa como entrada en un archivo shp de salida\n    '''\n    GRUPOS=\"tempGrupos.kea\"\n    RESULTADO=\"tempImg.kea\"\n    segutils.runShepherdSegmentation(entrada, GRUPOS, RESULTADO, minPxls=minPxls, distThres=distThres)\n    vectorutils.polygoniseRaster(RESULTADO,salida)\n    os.remove(GRUPOS)\n    os.remove(RESULTADO)\n\ndef segmenta_all_tiles(seg_crop, segmented_tiles, minPxls = 100, distThres = 100):\n    \"\"\"\n    :param seg_crop: folder with raster images prepared for segmentation\n    :param segmented_tiles: output folder for segmentation layers.\n    :return:\n    \"\"\"\n    def get_outputs(x):\n        out = x.split('.tif')[0][8:]\n        return(out)\n\n    list_segcrop = os.listdir(seg_crop)\n    list_forseg = list(map(lambda x: f\"{seg_crop}/{x}\", list_segcrop))\n    list_outputs = list(map(lambda x: f\"{segmented_tiles}/Segmented_{get_outputs(x)}.shp\", list_segcrop))\n    OUT = list(map(lambda x, y, min, dist: segmenta(entrada = x, salida = y),\n                   list_forseg,\n                   list_outputs,\n                   [minPxls] * len(list_forseg),\n                   [distThres] * len(list_forseg)\n                   ))\n\n\n\ndef merge_layers(inputFolder, outputFile, oformat=\"GPKG\", epsg=25830, informat=\"ESRI Shapefile\"):\n    \"\"\"\n    Merge layers tiles together\n    :param inputFolder: Input with layer tiles\n    :param outputFile: Output to be created\n    :param oformat: output file format\n    :param epsg: epsg of output file\n    :param informat: Input files format\n    :return:\n    \"\"\"\n    geometryType = ogr.wkbPolygon\n    driver = ogr.GetDriverByName(oformat)\n\n    srs = osr.SpatialReference()\n    srs.ImportFromEPSG(epsg)\n\n    if os.path.exists(outputFile):\n        driver.DeleteDataSource(outputFile)\n    out_ds = driver.CreateDataSource(outputFile)\n\n    # Creating output layer name\n    layer_name_tmp = outputFile.split(\".\")[0]\n    layer_name_tmp2 = layer_name_tmp.split(\"/\")\n    layer_name = layer_name_tmp2[len(layer_name_tmp2) - 1]\n\n    # Creating output layer\n    out_layer = out_ds.CreateLayer(layer_name, srs, geom_type=geometryType)\n\n    # Reading input layers\n    if type(inputFolder) is list:\n        list_shps = inputFolder\n    else:\n        list_layers = list(map(lambda x: f\"{inputFolder}/{x}\", os.listdir(inputFolder)))\n        if informat == \"ESRI Shapefile\":\n            list_shps = list(filter(lambda x: \"shp\" in x, list_layers))\n        else:\n            list_shps = list_layers\n\n    for shp in list_shps:\n        in_ds = ogr.Open(shp)\n        if in_ds is None: return (\"Flipao\")\n        in_layer = in_ds.GetLayer()\n        in_layer_defn = in_layer.GetLayerDefn()\n\n        # Add fields\n        nfields = in_layer_defn.GetFieldCount()\n        for i in range(0, nfields):\n            fieldDefn = in_layer_defn.GetFieldDefn(i)\n            out_layer.CreateField(fieldDefn)\n\n        # Get output layer definition\n        out_layer_defn = out_layer.GetLayerDefn()\n\n        for infeat in in_layer:\n            geom = infeat.GetGeometryRef().Clone()\n            ofeat = ogr.Feature(out_layer_defn)\n            ofeat.SetGeometry(geom)\n\n            # Get in all fields\n            for i in range(0, nfields):\n                # print(i)\n                ofield_name = out_layer_defn.GetFieldDefn(i).GetNameRef()\n                ofield_value = infeat.GetField(i)\n                ofeat.SetField(ofield_name, ofield_value)\n\n            out_layer.CreateFeature(ofeat)\n\n        del in_ds\n    out_layer.SyncToDisk()\n    del out_ds\n\n\ndef stacktodo(lidar_tifs, crop_stacks, crop_stackForstats):\n    \"\"\"\n    Stack all the information needed for modelling\n    :param lidar_tifs: Raster images derived from LiDAR pointclouds\n    :param crop_stacks: Stacks with all the information wanted\n    :param crop_stackForstats: Output stacks (tiles)\n    :return:\n    \"\"\"\n\n    def get_bandName_fromMetadata(data_source):\n        option_name = \"TIFFTAG_IMAGEDESCRIPTION\"\n        md = band.GetMetadata()\n        for k, v in md.items():\n            if k == option_name:\n                return (v)\n\n\n    def get_bandName_fromName(name):\n        out = name.split(\"_\")[0]\n        return (out)\n\n    def same_coordinates(a, b):\n        avariable, acoordinates, atile = a.split(\"_\")\n        bvariable, bcoordinates = b.split(\"_\")\n        bcoordinates = bcoordinates.split(\".tif\")[0]\n        if acoordinates == bcoordinates:\n            return (True)\n        else:\n            return (False)\n\n\n    def get_rid_of_path(x):\n        tmp = x.split(\"/\")\n        out = tmp[len(tmp)-1]\n        return(out)\n\n    def get_all_files_from_listoffolders(listfolders):\n        tmp = list(map(lambda x:\n                       list(map(lambda y:\n                                f\"{x}/{y}\",\n\n                                # Pass list of each folder inside listfolder (x)\n                                os.listdir(x)\n                                )),\n                       listfolders\n                       ))\n        out = sum(tmp, [])\n        return(out)\n\n\n    list_lidartif_folders = list(map(lambda x: f\"{lidar_tifs}/{x}\", os.listdir(lidar_tifs)))\n    list_lidar_files = get_all_files_from_listoffolders(list_lidartif_folders)\n    list_temporal_stacks = list(map(lambda x: f\"{crop_stacks}/{x}\", os.listdir(crop_stacks)))\n\n    lista2 = []\n    for temporal in list_temporal_stacks:\n        lista = [temporal]\n        for lidar_raster in list_lidar_files:\n            if same_coordinates(get_rid_of_path(temporal), get_rid_of_path(lidar_raster)):\n                lista.append(lidar_raster)\n\n        lista2.append(lista)\n\n    lists_toStack = list(filter(lambda x: len(x)>1, lista2))\n\n\n    for toStack in lists_toStack:\n        listarrays = []\n        listband_names = []\n        for tif in toStack:\n            tif_name = get_rid_of_path(tif)\n\n\n            ds = gdal.Open(tif)\n            nbands = ds.RasterCount\n            diccionario = {}\n\n\n            for bandi in range(1, nbands + 1):\n                band = ds.GetRasterBand(bandi)\n                if nbands > 1:\n                    band_name = get_bandName_fromMetadata(band)\n                else:\n\n                    band_name = get_bandName_fromName(tif_name)\n\n\n                arr = band.ReadAsArray()\n\n                diccionario[band_name] = arr\n\n            for k,v in diccionario.items():\n                listband_names.append(k)\n                listarrays.append(v)\n\n        variable, coordinatestif = tif_name.split(\"_\")\n        out_path = f\"{crop_stackForstats}/{coordinatestif}\"\n\n        arrays = np.stack(listarrays, axis = 2)\n        create_raster(in_ds = ds,\n                      fn = out_path,\n                      data = arrays,\n                      data_type = gdal.GDT_Float32,\n                      band_names = listband_names\n                      )\n        ds = None\n\n\ndef create_layer(output, feature_list,\n                 driver_name=\"GPKG\", epsg=25830,\n                 geom_type=ogr.wkbPolygon, data_type=ogr.OFTReal):\n    \"\"\"\n    output_name         -  Name of the shapefile to craete with extension\n    feature_dictionary  -  list with two elements, geometry and a list with a dictionary with the name of the field at the keys\n                            and its values at de values.\n    driver_name         -  driver to use. GPKG by default.\n    epsg                -  epsg code to assign projection\n    geom_type           -  geom type of the geometry suplied\n    data_type           -  data_type of the values\n    \"\"\"\n\n    # Getting name of the output without path and extension\n    output_layer_tmp = output.split(\"/\")\n    output_layer_tmp2 = output_layer_tmp[len(output_layer_tmp) - 1]\n    output_layer_name = output_layer_tmp2.split(\".\")[0]\n    #     print(output_layer_name)\n\n    # Getting srs\n    out_srs = osr.SpatialReference()\n    out_srs.ImportFromEPSG(epsg)\n    #     print(out_srs)\n\n    # create output layer\n    driver = ogr.GetDriverByName(driver_name)\n    if os.path.exists(output):\n        driver.DeleteDataSource(output)\n    out_ds = driver.CreateDataSource(output)\n    if out_ds is None:\n        print(\"output data source is None\")\n        return 1\n    out_layer = out_ds.CreateLayer(output_layer_name, geom_type=geom_type, srs=out_srs)\n\n    # very important matter to reset Reading after define out layer\n    out_layer.ResetReading()\n    #     print(out_layer)\n\n    # Iterate through list to get fields and create them\n    for feature in feature_list:\n        diccionario_tmp = feature[1]\n        diccionario = diccionario_tmp[0]\n\n        for field in diccionario.keys():\n            outFieldDefn = ogr.FieldDefn(field, data_type)\n            out_layer.CreateField(outFieldDefn)\n\n    # Get Layer Definition\n    out_layerDefn = out_layer.GetLayerDefn()\n    #     print(out_layerDefn.GetGeomFieldDefn())\n    #     print(out_layerDefn)\n\n    # Iterate through list to get geometris, fields and values\n    it = 0\n    for feature in feature_list:\n        geomwkt = feature[0]\n        geom = ogr.CreateGeometryFromWkt(geomwkt)\n\n        diccionario_tmp = feature[1]\n        diccionario = diccionario_tmp[0]\n\n        ofeat = ogr.Feature(out_layerDefn)\n        ofeat.SetGeometry(geom)\n        for field, value in diccionario.items():\n            ofeat.SetField(field, value)\n\n        #             print(field, value*1.0)\n\n        out_layer.CreateFeature(ofeat)\n\n    out_layer.SyncToDisk()\n    out_ds = None\n\n\ndef getting_stats(src_filename, layer_filename, output, statistics = \"mean\", name_band = None, all_touched = True,\n                  all_features = False):\n    \"\"\"\n    Generate spatial statistics of the segments\n\n    :param src_filename:\n    :param layer_filename:\n    :param output:\n    :param statistics: mean by default\n    :param name_band:\n    :param all_touched:\n    :param all_features:\n    :return:\n    \"\"\"\n\n    def get_band_name(band):\n        option_name = \"TIFFTAG_IMAGEDESCRIPTION\"\n        md = band.GetMetadata()\n        for k, v in md.items():\n            if k == option_name:\n                return (v)\n\n    #     src_filename = \"tmp/image_tiles/crop_stacks/tStack_360000.0-4358000.0_T30SUJ.tif\"\n    #     layer_filename = \"tmp/image_tiles/segmented_tiles/Segmented_360000.0-4358000.0_T30SUJ.shp\"\n\n\n    lds = ogr.Open(layer_filename)\n    layer = lds.GetLayer()\n    lista_diccionarios = []\n\n    for feat in layer:\n        lista_features = []\n        geom = feat.GetGeometryRef()\n        geomwkt = geom.ExportToWkt()\n        lista_features.append(geomwkt)\n\n        geomjson = geom.ExportToJson()\n\n        src_ds = gdal.Open(src_filename)\n        RasterCount = src_ds.RasterCount\n        dictmp = {}\n        if all_features:\n            nField = feat.GetFieldCount()\n            for fieldi in range(0, nField):\n                fieldname = feat.GetFieldDefnRef(fieldi).GetName()\n                # print(fieldname)\n                fieldvalue = feat.GetField(fieldi)\n                dictmp[fieldname] = fieldvalue\n\n        for i in range(1, RasterCount + 1):\n            banda = src_ds.GetRasterBand(i)\n            if name_band is None:\n                band_name = get_band_name(banda)\n            else:\n                band_name = name_band\n\n            stats = rasterstats.zonal_stats(geomjson, src_filename, stats = statistics, band=i, all_touched = all_touched)\n\n            for k, v in stats[0].items():\n                field_name = f\"{band_name}_{k}\"\n                dictmp[field_name] = v\n\n        tmp = [dictmp]\n        lista_features.append(tmp)\n        lista_diccionarios.append(lista_features)\n\n    create_layer(output, lista_diccionarios)\n\n    del lds\n    del src_ds\n\n\n\ndef getting_stats_toFolder(crop_stackForStats, segmented_tiles, segmented_stats, name_band = None,\n                           statistics = \"mean\", all_touched = True, all_features = False):\n    \"\"\"\n    Apply getting stats to a folder\n    :param crop_stackForStats:\n    :param segmented_tiles:\n    :param segmented_stats:\n    :param name_band:\n    :param statistics:\n    :param all_touched:\n    :param all_features:\n    :return:\n    \"\"\"\n    diccionario = {}\n    for segments in os.listdir(segmented_tiles):\n        if \"shp\" in segments:\n            name, coordinates, tileext = segments.split(\"_\")\n            tile = tileext.split(\".\")[0]\n            for raster_stack in os.listdir(crop_stackForStats):\n                #                     print(raster_stack)\n                #                     if tile in raster_stack:\n                if coordinates in raster_stack:\n                    diccionario[segments] = raster_stack\n\n        if \"gpkg\" in segments:\n            name, coordinates, tileext = segments.split(\"_\")\n            tile = tileext.split(\".\")[0]\n            if \".tif\" in crop_stackForStats:\n                raster_stack = crop_stackForStats\n                diccionario[segments] = raster_stack\n\n            else:\n                for raster_stack in os.listdir(crop_stackForStats):\n                    #                     print(raster_stack)\n                    #                     if tile in raster_stack:\n                    if coordinates in raster_stack:\n                        diccionario[segments] = raster_stack\n\n    for k, v in diccionario.items():\n        value, coordinates, tiletmp = k.split(\"_\")\n        tile = tiletmp.split(\".\")[0]\n        out_name = f\"segStats_{coordinates}_{tile}.gpkg\"\n        print(out_name)\n        segStats_file = f\"{segmented_stats}/{out_name}\"\n        if \".tif\" in crop_stackForStats:\n            raster_stack_file = raster_stack\n        else:\n            raster_stack_file = f\"{crop_stackForStats}/{v}\"\n        segmented_file = f\"{segmented_tiles}/{k}\"\n\n        getting_stats(raster_stack_file, segmented_file, segStats_file, name_band = name_band, statistics = statistics,\n                      all_touched = all_touched, all_features = all_features)\n\n\n\ndef joinTraining_with_Stats(forTraining, output_training, segmented_stats, training_field = \"CODETYPE\"):\n    \"\"\"\n    Join training dataset with th Stats\n    :param forTraining: Training dataset\n    :param output_training:\n    :param segmented_stats:\n    :param training_field:\n    :return:\n    \"\"\"\n\n    ft_ds = ogr.Open(forTraining)\n    ft_layer = ft_ds.GetLayer()\n\n    listof_SegStats = list(map(lambda x: f\"{segmented_stats}/{x}\", os.listdir(segmented_stats)))\n    lista_features = []\n    for SegStats in listof_SegStats:\n    #     print(SegStats)\n        ss_ds = ogr.Open(SegStats)\n        ss_layer = ss_ds.GetLayer()\n        ss_layerDefn = ss_layer.GetLayerDefn()\n\n        # print(1)\n\n\n        for ft_feat in ft_layer:\n            ft_geom = ft_feat.GetGeometryRef()\n            ft_geom_wkt = ft_geom.ExportToWkt()\n\n            for ss_feat in ss_layer:\n                ss_geom = ss_feat.GetGeometryRef()\n\n                lfeatures = []\n                diccionario = {}\n                if ft_geom.Contains(ss_geom):\n    #                 print(\"ja\")\n                    lfeatures.append(ft_geom_wkt)\n\n                    for i in range(ft_feat.GetFieldCount()):\n                        field_name = ft_feat.GetFieldDefnRef(i).name\n                        field_value = ft_feat.GetField(field_name)\n                        if field_name == training_field:\n                            diccionario[field_name] = field_value\n\n                    for i in range(ss_feat.GetFieldCount()):\n                        field_name = ss_feat.GetFieldDefnRef(i).name\n                        field_value = ss_feat.GetField(field_name)\n                        diccionario[field_name] = field_value\n\n\n                    lfeatures.append([diccionario])\n\n                if len(lfeatures) > 0:\n                    lista_features.append(lfeatures)\n\n\n\n\n    #     print(\"\\n\")\n\n    del ft_ds\n    del ss_ds\n\n    # print(output_training)\n    create_layer(output_training, lista_features)\n\n\ndef modela(archivoEntrenado, training_field):\n    \"\"\"\n    Model creation\n    :param archivoEntrenado: Trained file\n    :param training_field:  Training target\n    :return:\n    \"\"\"\n    df = gpd.read_file(archivoEntrenado)\n    columns = list(filter(lambda x: x not in [training_field, \"geometry\"], df.columns))\n    y = df[training_field]\n    X = df[columns]\n\n    clasificador = RandomForestClassifier(n_estimators = 30)\n    modelo = clasificador.fit(X, y)\n    return(modelo)\n\ndef predecir(modelo, tile_for_predict, output, epsg = 25830, training_field = \"CODETYPE\"):\n    \"\"\"\n    Prediction based on model\n    :param modelo: Model\n    :param tile_for_predict: Tile\n    :param output:\n    :param epsg:\n    :param training_field:\n    :return:\n    \"\"\"\n    df_seg = gpd.read_file(tile_for_predict)\n    columns = list(filter(lambda x: x not in [training_field, \"geometry\"], df_seg.columns))\n    geometry = df_seg[\"geometry\"]\n    df_topredict = df_seg[columns]\n    prediction = modelo.predict(df_topredict)\n    df_topredict[training_field] = prediction\n    df_topredict[\"geometry\"] = geometry\n    crs = {'init': f'epsg:{epsg}'}\n    final = gpd.GeoDataFrame(df_topredict, geometry = geometry, crs = crs)\n    final.to_file(output, driver = \"GPKG\")\n\n\ndef model_and_predict(archivoEntrenado, tile_for_predict, output,\n                      pca=False, epsg=25830, training_field=\"CODETYPE\"):\n\n    \"\"\"\n    Compute modelling and prediction at the same time\n    :param archivoEntrenado:\n    :param tile_for_predict:\n    :param output:\n    :param pca:\n    :param epsg:\n    :param training_field:\n    :return:\n    \"\"\"\n\n    # Modeling\n    df = gpd.read_file(output_training)\n    columns = list(filter(lambda x: x not in [training_field, \"geometry\"], df.columns))\n    y = df[training_field]\n    X = df[columns]\n    if pca:\n        pca.fit(X)\n        X = pca.transform(X)\n\n    clasificador = RandomForestClassifier(n_estimators=30)\n    modelo = clasificador.fit(X, y)\n\n    # Predicting\n    df_seg = gpd.read_file(tile_for_predict)\n    columns = list(filter(lambda x: x not in [training_field, \"geometry\"], df_seg.columns))\n    geometry = df_seg[\"geometry\"]\n    df_topredict = df_seg[columns]\n    if pca:\n        df_topredict = pca.transform(df_topredict)\n\n    prediction = modelo.predict(df_topredict)\n    print(type(prediction))\n    #     df_topredict[training_field] = prediction\n    diccionario = {training_field: prediction}\n    df_topredict = pd.DataFrame(data=diccionario)\n    df_topredict[\"geometry\"] = geometry\n    crs = {'init': f'epsg:{epsg}'}\n    final = gpd.GeoDataFrame(df_topredict, geometry=geometry, crs=crs)\n    final.to_file(output, driver=\"GPKG\")\n\n\n\ndef prediction_to_folder(modelo, tile_for_predict, output):\n    \"\"\"\n    Apply prediction to folder\n\n    :param modelo:\n    :param tile_for_predict:\n    :param output:\n    :return:\n    \"\"\"\n    def prediction_outputName(a):\n        # print(a)\n        tmp = a.split(\"/\")\n        tmp2 = tmp[len(tmp)-1]\n        variable, coordinates, tilegpkg = tmp2.split(\"_\")\n        out = f\"Pred_{coordinates}_{tilegpkg}\"\n        return(out)\n\n\n    lista_SegStats = list(map(lambda x: f\"{tile_for_predict}/{x}\", os.listdir(tile_for_predict)))\n    lista_predOut = list(map(lambda x: f\"{output}/{prediction_outputName(x)}\", lista_SegStats))\n\n    aaaaout = list(map(lambda x,y,z: predecir(x, y, z),\n                       [modelo]*len(lista_SegStats),\n                       lista_SegStats,\n                       lista_predOut\n                      ))\n\n\ndef forest_fuel(input_layer, output_layer, training_field=\"CODETYPE\", driver_name=\"GPKG\",\n                epsg=25830, geom_type=ogr.wkbPolygon, data_type=ogr.OFTReal\n                ):\n\n    \"\"\"\n    Forest fuel classification\n\n    :param input_layer: Land cover map (with forests)\n    :param output_layer:\n    :param training_field:\n    :param driver_name:\n    :param epsg:\n    :param geom_type:\n    :param data_type:\n    :return:\n    \"\"\"\n\n    print(input_layer)\n    print(output_layer)\n    print(\"\\n\")\n\n    # We must open the file\n    in_ds = ogr.Open(input_layer)\n    in_layer = in_ds.GetLayer()\n    in_layerdefn = in_layer.GetLayerDefn()\n    nfields = in_layerdefn.GetFieldCount()\n\n    lista_diccionarios = []\n    for feature in in_layer:\n\n        geom = feature.GetGeometryRef().ExportToWkt()\n\n        # Iterating through fields\n        diccionario = {}\n\n        nfields = feature.GetFieldCount()\n        for fieldi in range(nfields):\n            nameField = feature.GetFieldDefnRef(fieldi).GetName()\n            if nameField == training_field:\n                valueField = feature.GetField(fieldi)\n                diccionario[training_field] = valueField\n        for i in range(nfields):\n            field_name = in_layerdefn.GetFieldDefn(i).name\n            #             print(field_name)\n            if \"mean\" in field_name:\n                if field_name in [\"TCH_mean\", \"SCH_mean\", \"FCC_mean\", \"SCC_mean\", \"TCC_mean\", training_field]:\n                    field_value = feature.GetField(field_name)\n                    diccionario[field_name] = field_value\n\n        if diccionario[training_field] in [1, 2, 5, 9]:\n            fuel_type = 0\n        else:\n            if diccionario[\"SCC_mean\"] < 60:\n                fuel_type = 1\n            if diccionario[\"SCC_mean\"] >= 60 and diccionario[\"TCC_mean\"] < 50:\n                meanHeight = np.mean([diccionario[\"TCH_mean\"], diccionario[\"SCH_mean\"]])\n                if meanHeight >= 0.3 and meanHeight <= 0.6: fuel_type = 2\n                if meanHeight > 0.6 and meanHeight <= 2.0: fuel_type = 3\n                #                 if meanHeight > 2.0 and meanHeight <= 4.0: fuel_type = 4\n                if meanHeight > 2.0:\n                    fuel_type = 4\n                else:\n                    fuel_type = 1\n            if diccionario[\"TCC_mean\"] >= 50:\n                if diccionario[\"SCC_mean\"] < 30: fuel_type = 5\n                if diccionario[\"SCC_mean\"] >= 30:\n                    diffHeight = diccionario[\"TCH_mean\"] - diccionario[\"SCH_mean\"]\n                    if diffHeight >= 0.5: fuel_type = 6\n                    if diffHeight < 0.5: fuel_type = 7\n\n        diccionario[\"fuel_type\"] = fuel_type\n        lista_diccionarios.append([geom, [diccionario]])\n\n    #         print(\"\\n\")\n\n    in_ds = None\n\n    create_layer(output_layer, lista_diccionarios, driver_name=driver_name,\n                 epsg=epsg, geom_type=geom_type, data_type=data_type\n                 )\n\n\ndef forest_fuel_to_folder(input_folder, output_folder):\n\n    \"\"\"\n    Application of forest_fuel to folders\n    :param input_folder:\n    :param output_folder:\n    :return:\n    \"\"\"\n\n    def ForestFuel_outputName(a):\n        tmp = a.split(\"/\")\n        tmp2 = tmp[len(tmp) - 1]\n        variable, coordinates, tilegpkg = tmp2.split(\"_\")\n        out = f\"ForestFuel_{coordinates}_{tilegpkg}\"\n        return (out)\n\n    listinputs = list(map(lambda x: f\"{input_folder}/{x}\", os.listdir(input_folder)))\n    listoutputs = list(map(lambda x: f\"{output_folder}/{ForestFuel_outputName(x)}\", listinputs))\n    #     print(listoutputs)\n\n    jcintasr = list(map(lambda x, y: forest_fuel(x, y), listinputs, listoutputs))\n\n\ndef pendiente(src,dst=None):\n    \"\"\"\n    Pendiente computation from DEM\n    :param src: DEM\n    :param dst: output\n    :return:\n    \"\"\"\n    try:\n        fichero=richdem.LoadGDAL(src)\n    except:\n        print(\"No existe el archivo\")\n        return False\n    try:\n        #se calcula la pendiente en radianes\n        pendiente=richdem.TerrainAttribute(fichero, attrib='slope_percentage')\n    except:\n        print(\"El archivo no tiene un formato v\u00e1lido\")\n        return False\n    if not dst:\n        dst=src.replace(\".tif\",\"_pendiente.tif\")\n    richdem.SaveGDAL(dst,pendiente)\n    print(\"Se ha calculado la pendiente: \"+dst)\n    return True\n\n\ndef orientacion(src,dst=None):\n    \"\"\"\n    Aspect computation from DEM\n    :param src: DEM\n    :param dst: output\n    :return:\n    \"\"\"\n    try:\n        fichero=richdem.LoadGDAL(src)\n    except:\n        print(\"No existe el archivo\")\n        return False\n    try:\n        #se calcula la orientaci\u00f3n en grados\n        pendiente=richdem.TerrainAttribute(fichero, attrib='aspect')\n    except:\n        print(\"El archivo no tiene un formato v\u00e1lido\")\n        return False\n    if not dst:\n        dst=src.replace(\".tif\",\"_orientacion.tif\")\n    richdem.SaveGDAL(dst,pendiente)\n    print(\"Se ha calculado la orientaci\u00f3n: \"+dst)\n    return True\n\ndef slope_to_folders(las_tiles):\n    \"\"\"\n    Apply slope to folder\n    :param las_tiles:\n    :return:\n    \"\"\"\n    variable = \"slope\"\n    def getFile_FromPath(a):\n        b = a.split(\"/\")\n        b = b[len(b)-1]\n        return(b)\n\n    list_coordinates_folder = list(map(lambda x: f\"{las_tiles}/{x}\", os.listdir(las_tiles)))\n    for coordinates_folder in list_coordinates_folder:\n        coordinates = getFile_FromPath(coordinates_folder)\n        tmp = list(map(lambda x: f\"{coordinates_folder}/{x}\", os.listdir(coordinates_folder)))\n        dem_folder = list(filter(lambda x: \"DEM\" in x, tmp)) # DEM folder\n        demFolder_insides = list(map(lambda x: f\"{dem_folder[0]}/{x}\", os.listdir(dem_folder[0])))\n        dem_tifs = list(filter(lambda x: \".tif\" in x, demFolder_insides))\n\n        output_folder = f\"{las_tiles}/{coordinates}/{variable}\"\n        os.makedirs(output_folder, exist_ok = True)\n        output_files = list(map(lambda x: f\"{output_folder}/slope_{getFile_FromPath(x)[4:]}\", dem_tifs))\n\n        diccionario = list(map(lambda x,y: {x:y}, dem_tifs, output_files))\n        for dicc in diccionario:\n            for k,v in dicc.items():\n                pendiente(k,v)\n\ndef aspect_to_folders(las_tiles):\n    \"\"\"\n    Apply aspect to folders\n    :param las_tiles:\n    :return:\n    \"\"\"\n    variable = \"aspect\"\n\n    def getFile_FromPath(a):\n        b = a.split(\"/\")\n        b = b[len(b) - 1]\n        return (b)\n\n    list_coordinates_folder = list(map(lambda x: f\"{las_tiles}/{x}\", os.listdir(las_tiles)))\n    for coordinates_folder in list_coordinates_folder:\n        coordinates = getFile_FromPath(coordinates_folder)\n        tmp = list(map(lambda x: f\"{coordinates_folder}/{x}\", os.listdir(coordinates_folder)))\n        dem_folder = list(filter(lambda x: \"DEM\" in x, tmp))  # DEM folder\n        demFolder_insides = list(map(lambda x: f\"{dem_folder[0]}/{x}\", os.listdir(dem_folder[0])))\n        dem_tifs = list(filter(lambda x: \".tif\" in x, demFolder_insides))\n\n        output_folder = f\"{las_tiles}/{coordinates}/{variable}\"\n        #         print(output_folder)\n        os.makedirs(output_folder, exist_ok=True)\n        output_files = list(map(lambda x: f\"{output_folder}/aspect_{getFile_FromPath(x)[4:]}\", dem_tifs))\n\n        diccionario = list(map(lambda x, y: {x: y}, dem_tifs, output_files))\n        for dicc in diccionario:\n            for k, v in dicc.items():\n                orientacion(k, v)\n\ndef reclass_aspect(inputfile, outputfile):\n    \"\"\"\n    Reclass aspect into North (4), East (3), South (2) and West (1)\n    :param inputfile:\n    :param outputfile:\n    :return:\n    \"\"\"\n    ds = gdal.Open(inputfile)\n    arr = ds.GetRasterBand(1).ReadAsArray()\n    arr2 = np.select([(arr >= 45) & (arr < 135),\n                      (arr >= 135) & (arr < 225),\n                      (arr >= 225) & (arr < 315),\n                      (arr >= 315) | (arr < 45)],\n                     [1, 2, 3, 4] # 1 = W, 2 = S, 3 = E, 4 = N\n                     )\n    create_raster(ds, outputfile, arr2, data_type = gdal.GDT_Int16)\n    ds = None\n\n\ndef reclass_aspect_to_folder(lidar_tifs, variable_folder = \"aspect\"):\n    \"\"\"\n    Apply reclassification aspect to folder\n    :param lidar_tifs:\n    :param variable_folder:\n    :return:\n    \"\"\"\n    def getFile_FromPath(a):\n        b = a.split(\"/\")\n        b = b[len(b) - 1]\n        return (b)\n\n    out = \"aspect_reclass\"\n    input_folder = f\"{lidar_tifs}/{variable_folder}\"\n    output_folder = f\"{lidar_tifs}/aspect_reclass\"\n    os.makedirs(output_folder, exist_ok = True)\n\n    list_diccionarios = list(map(lambda x: {f\"{input_folder}/{x}\":\n                                            f\"{output_folder}/aspectReclassed{getFile_FromPath(x)[6:]}\"},\n                                 os.listdir(input_folder)\n                                ))\n\n    for d in list_diccionarios:\n        for k,v in d.items():\n            reclass_aspect(k, v)\n\n\ndef read_temperaturas(database, table, periodo, out_file,\n                      user=\"postgres\", password=\"postgres\",\n                      host = \"localhost\", port = \"5432\",\n                      layer=None, extent=None, srs=25830,\n                      temperatura_variable=\"tm_mes\", temperatura_name=\"tmed\",\n                      rango_de_a\u00f1os=15, outdriver=\"GPKG\"):\n\n    \"\"\"\n    Read temperatures from a postgis database\n    :param database: database name\n    :param table: table name\n    :param periodo: Span of years to create the mean\n    :param out_file: Output file\n    :param user: user\n    :param password: password\n    :param host: host\n    :param port: port\n    :param layer: subset with layer extent\n    :param extent: subset with extent\n    :param srs: Define an srs\n    :param temperatura_variable: name of the variable\n    :param temperatura_name: name of out variable\n    :param rango_de_a\u00f1os: Minimum number of years to be considered\n    :param outdriver: format of the output file\n    :return:\n    \"\"\"\n\n    if layer is not None:\n        extent = get_layerextent(layer)\n\n    if extent is not None:\n        sql_envelope = f\"{extent}, {srs}\"\n\n    # Conexi\u00f3n con la base de datos\n    connection = psycopg2.connect(database=database,\n                                  user=user, password=password,\n                                  port = port, host = host\n                                  )\n    cursor = connection.cursor()\n\n    # Consulta sql para un periodo de tiempo\n    p1 = periodo[0]\n    p2 = periodo[1]\n    sql_query = f\"\"\"WITH subst AS (\n                        select\n                                indicativo,\n                                count(distinct(year)) as len\n                        from\n                                {table}\n                        where\n                                variable = '{temperatura_variable}'\n                                and\n                                year between {p1} and  {p2}\n                        group by\n                                indicativo\n                        )\n                    select\n                        a.indicativo,\n                        avg(a.values)/10 as {temperatura_name},\n                        st_astext(a.geom) as geom\n                    from\n                        {table} as a\n                    inner join\n                        subst as b\n                    using\n                        (indicativo)\n                    where\n                        a.year between {p1} and {p2}\n                        and\n                        b.len >= {rango_de_a\u00f1os}\n                        and\n                        a.variable = '{temperatura_variable}'\n                        and\n                        st_intersects(a.geom, st_MakeEnvelope({sql_envelope}))\n                    group by\n                        a.indicativo,\n                        a.geom;\"\"\"\n    cursor.execute(sql_query)\n\n    # Guardando puntos de temperatura en una capa.\n    lista = []\n    for indicativo, temperatura, geom in cursor:\n        data = {'indicativo': indicativo, f'{temperatura_name}': temperatura, 'geometry': shp.wkt.loads(geom)}\n        lista.append(data)\n\n    gdf = gpd.GeoDataFrame(lista, crs=f'epsg:{srs}').set_index('indicativo')\n    gdf[f'{temperatura_name}'] = gdf[f'{temperatura_name}'].astype(\"float\")\n    gdf.to_file(out_file, driver=outdriver)\n    print(\"Archivo creado\")\n\n\n\ndef get_extent_from_r(layer, dist):\n\n    \"\"\"\n    Get extent from a layer with R\n    :param layer:\n    :param dist:\n    :return:\n    \"\"\"\n\n    utils = importr(\"utils\")\n    utils.chooseCRANmirror(ind=1)\n    base = importr(\"base\")\n\n\n    packages = (\"sf\")\n    names_to_install = []\n    for pkg in packages:\n         if not rpackages.isinstalled(pkg):\n             names_to_install.append(pkg)\n\n\n    if len(names_to_install) > 0:\n        utils.install_packages(StrVector(names_to_install))\n\n    robjects.r('''\n        source(\"get_layerextent.R\")\n    ''')\n\n    get_layeRextent = robjects.globalenv['get_extent']\n\n    extent = get_layeRextent(layer = layer, dist = dist)\n    out_extent = f\"{extent[0]}, {extent[1]}, {extent[2]}, {extent[3]}\"\n    return(out_extent)\n\n\ndef TempRegKrig(points, var, formula, mdt, lat, dist, output, res = 1000, epsg = 25830):\n\n    \"\"\"\n    Compute regression kriging with R\n\n    :param points: Temperature points\n    :param var: Temperature variable name\n    :param formula: Formula for regression kiring as character\n    :param mdt: mdt raster path\n    :param lat: latitude raster path\n    :param dist: distance raster path\n    :param output: output\n    :param res: resolution\n    :param epsg: espeg code to define projection\n    :return:\n    \"\"\"\n\n    utils = importr(\"utils\")\n    utils.chooseCRANmirror(ind=1)\n    base = importr(\"base\")\n    raster = importr(\"raster\")\n\n    # Check r packages in use\n    packages = (\"sf\", \"raster\", \"automap\")\n    names_to_install = []\n    for pkg in packages:\n        if not rpackages.isinstalled(pkg):\n            names_to_install.append(pkg)\n    if len(names_to_install) > 0:\n        utils.install_packages(StrVector(names_to_install))\n\n    # Load R script\n    robjects.r(f'''\n        source(\"kriging.R\")\n    ''')\n\n    # print(1)\n    # print(type(mdt))\n    rasterlist = base.list(mdt = mdt, lat = lat, dist = dist)\n    # print(2)\n    # print(rasterlist)\n    doReKrig = robjects.globalenv['doRegKrig']\n    rekriged = doReKrig(points = points, var = var, formula = formula, listrasters = rasterlist, res = res, epsg = epsg)\n\n    raster.writeRaster(rekriged, output, overwrite = True)\n\n\ndef read_humedad(database, table, periodo, out_file,\n                 user=\"postgres\", password=\"postgres\",\n                 host = \"localhost\", port = \"5432\",\n                 humidity_name = \"rehumidity\",\n                 layer=None, extent=None, srs=25830,\n                 rango_de_a\u00f1os=15, outdriver=\"GPKG\"):\n    \"\"\"\n    Read humidty points from a postgis database\n    :param database:\n    :param table:\n    :param periodo:\n    :param out_file:\n    :param user:\n    :param password:\n    :param host:\n    :param port:\n    :param humidity_name: name of the variable\n    :param layer:\n    :param extent:\n    :param srs:\n    :param rango_de_a\u00f1os: Minimum span of years to be considered\n    :param outdriver:\n    :return:\n    \"\"\"\n\n    if layer is not None:\n        extent = get_layerextent(layer)\n\n    if extent is not None:\n        sql_envelope = f\"{extent}, {srs}\"\n\n    # Conexi\u00f3n con la base de datos\n    connection = psycopg2.connect(database=database,\n                                  user=user, password=password,\n                                  port = port, host = host\n                                  )\n    cursor = connection.cursor()\n\n    # Consulta sql para un periodo de tiempo\n    p1 = periodo[0]\n    p2 = periodo[1]\n    sql_query = f\"\"\"WITH subst AS (\n                        select\n                                indicativo,\n                                count(distinct(year)) as len\n                        from\n                                {table}\n                        where\n                                year between {p1} and  {p2}\n                        group by\n                                indicativo\n                        )\n                    select\n                        a.indicativo,\n                        avg(a.humidity)/10 as {humidity_name},\n                        st_astext(a.geom) as geom\n                    from\n                        {table} as a\n                    inner join\n                        subst as b\n                    using\n                        (indicativo)\n                    where\n                        a.year between {p1} and {p2}\n                        and\n                        b.len >= {rango_de_a\u00f1os}\n                        and\n                        st_intersects(a.geom, st_MakeEnvelope({sql_envelope}))\n                    group by\n                        a.indicativo,\n                        a.geom;\"\"\"\n    cursor.execute(sql_query)\n\n    # Guardando puntos de temperatura en una capa.\n    lista = []\n    for indicativo, temperatura, geom in cursor:\n        data = {'indicativo': indicativo, f'{humidity_name}': temperatura, 'geometry': shp.wkt.loads(geom)}\n        lista.append(data)\n\n    gdf = gpd.GeoDataFrame(lista, crs=f'epsg:{srs}').set_index('indicativo')\n    gdf[f'{humidity_name}'] = gdf[f'{humidity_name}'].astype(\"float\")\n    gdf.to_file(out_file, driver=outdriver)\n    print(\"Archivo creado\")\n\n\ndef HumOKrig(points, var, output, res = 1000, epsg = 25830):\n\n    \"\"\"\n    Compute simple kriging to humidity interpolation\n    :param points: points layer path\n    :param var: humidity variable name\n    :param output: output path\n    :param res: resolution\n    :param epsg: EPSG code to define projection\n    :return:\n    \"\"\"\n\n    utils = importr(\"utils\")\n    utils.chooseCRANmirror(ind=1)\n    base = importr(\"base\")\n\n    # Check r packages in use\n    packages = (\"sf\", \"raster\", \"automap\")\n    names_to_install = []\n    for pkg in packages:\n        if not rpackages.isinstalled(pkg):\n            names_to_install.append(pkg)\n    if len(names_to_install) > 0:\n        utils.install_packages(StrVector(names_to_install))\n\n    # Load R script\n    robjects.r(f'''\n        source(\"kriging.R\")\n    ''')\n\n    # print(1)\n    # print(type(mdt))\n    # rasterlist = base.list(mdt = mdt, lat = lat, dist = dist)\n    # print(2)\n    # print(rasterlist)\n    doKrig = robjects.globalenv['doKrig']\n    kriged = doKrig(points = points, var = var, res = res, epsg = epsg)\n    raster = importr(\"raster\")\n    raster.writeRaster(kriged, output, overwrite = True)\n\n\n# Reference fuel moisture\ndef rfm(temperature, reH):\n    \"\"\"\n    Compute Reference Fuel Moisture for Ignition Probability Computation\n    :param temperature:\n    :param reH:\n    :return:\n    \"\"\"\n    if temperature <= -1.5:\n        i = 0\n    if temperature > -1.5 and temperature <= 10:\n        i = 1\n    if temperature > 10 and temperature <= 20:\n        i = 2\n    if temperature > 20 and temperature <= 31:\n        i = 3\n    if temperature > 31 and temperature <= 42:\n        i = 4\n    if temperature > 42:\n        i = 5\n\n    if reH < 5:\n        j = 0\n    if reH >= 5 and reH < 10:\n        j = 1\n    if reH >= 10 and reH < 15:\n        j = 2\n    if reH >= 15 and reH < 20:\n        j = 3\n    if reH >= 20 and reH < 25:\n        j = 4\n    if reH >= 25 and reH < 30:\n        j = 5\n    if reH >= 30 and reH < 35:\n        j = 6\n    if reH >= 35 and reH < 40:\n        j = 7\n    if reH >= 40 and reH < 45:\n        j = 8\n    if reH >= 45 and reH < 50:\n        j = 9\n    if reH >= 50 and reH < 55:\n        j = 10\n    if reH >= 55 and reH < 60:\n        j = 11\n    if reH >= 60 and reH < 65:\n        j = 12\n    if reH >= 65 and reH < 70:\n        j = 13\n    if reH >= 70 and reH < 75:\n        j = 14\n    if reH >= 75 and reH < 80:\n        j = 15\n    if reH >= 80 and reH < 85:\n        j = 16\n    if reH >= 85 and reH < 90:\n        j = 17\n    if reH >= 90 and reH < 95:\n        j = 18\n    if reH >= 95 and reH < 100:\n        j = 19\n    if reH >= 100:\n        j = 20\n\n    RFM = np.array([[1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8, 8, 9, 9, 10, 11, 12, 12, 13, 13, 14],\n                    [1, 2, 2, 3, 4, 5, 5, 6, 7, 7, 7, 8, 9, 9, 10, 10, 11, 12, 13, 13, 13],\n                    [1, 2, 2, 3, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 11, 12, 12, 12, 13],\n                    [1, 1, 2, 2, 3, 4, 5, 5, 6, 7, 7, 8, 8, 8, 9, 10, 10, 11, 12, 12, 13],\n                    [1, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 8, 8, 9, 10, 10, 11, 12, 12, 13],\n                    [1, 1, 2, 2, 3, 4, 4, 5, 6, 7, 7, 8, 8, 8, 9, 10, 10, 11, 12, 12, 12]]\n                   )\n\n    out = RFM[i, j]\n    return (out)\n\n\ndef dfm_corrections(slope, aspect, shading, month_number):\n    \"\"\"\n    Compute correction for rfm\n\n    :param slope:\n    :param aspect:\n    :param shading: Shading value (1 for tree forests, 0 for everything else)\n    :param month_number: Number of the month\n    :return:\n    \"\"\"\n\n    # Slope is i\n    # Aspect is j\n    # Shading is z\n    if month_number in [5, 6, 7]:\n        tmp1 = np.array([[0, 0, 0, 0], [1, 0, 1, 1]])\n        tmp2 = np.array([[3, 3, 3, 3], [3, 3, 3, 3]])\n        DFMCorrections = np.stack([tmp1, tmp2], axis=2)\n\n    if month_number in [2, 3, 4, 8, 9, 10]:\n        tmp1 = np.array([[1, 1, 1, 1], [3, 1, 1, 2]])\n        tmp2 = np.array([[4, 4, 4, 4], [4, 4, 4, 4]])\n        DFMCorrections = np.stack([tmp1, tmp2], axis=2)\n\n    if month_number in [11, 12, 1]:\n        tmp1 = np.array([[3, 3, 3, 3], [5, 2, 1, 4]])\n        tmp2 = np.array([[5, 5, 5, 5], [5, 5, 5, 5]])\n        DFMCorrections = np.stack([tmp1, tmp2], axis=2)\n\n    if slope <= 30: i = 0\n    if slope > 30: i = 1\n\n    if np.round(aspect) == 1.0: j = 3\n    if np.round(aspect) == 2.0: j = 2\n    if np.round(aspect) == 3.0: j = 1\n    if np.round(aspect) == 4.0: j = 0\n\n    if shading == 0: z = 0\n    if shading == 1: z = 1\n\n    out = DFMCorrections[i, j, z]\n    return (out)\n\n\ndef pig(temperature, fdmp, shading):\n    \"\"\"\n    Compute Ignition Probability from forest_fuel type\n    :param temperature: temperature value\n    :param fdmp: rfm + dfm_correction\n    :param shading: Shading value (1 for tree forests, 0 for everything else)\n    :return:\n    \"\"\"\n\n    # Temperature == i\n    if temperature >= 43:\n        i = 0\n    if temperature >= 37 and temperature < 43:\n        i = 1\n    if temperature >= 32 and temperature < 37:\n        i = 2\n    if temperature >= 26 and temperature < 32:\n        i = 3\n    if temperature >= 21 and temperature < 26:\n        i = 4\n    if temperature >= 15 and temperature < 21:\n        i = 5\n    if temperature >= 10 and temperature < 15:\n        i = 6\n    if temperature >= 4 and temperature < 10:\n        i = 7\n    if temperature < 4:\n        i = 8\n\n    # FDFM == j\n    j = fdmp - 2  # It starts on 2 and go up to 17, but it will index 0 based.\n\n    # shading == z\n    if shading == 0: z = 0\n    if shading == 1: z = 1\n\n    PIG_0 = np.array([[100, 100, 80, 70, 60, 60, 50, 40, 40, 30, 30, 20, 20, 20, 20, 10],\n                      [100, 90, 80, 70, 60, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10],\n                      [100, 90, 80, 70, 60, 50, 40, 40, 30, 30, 30, 20, 20, 20, 10, 10],\n                      [100, 90, 80, 70, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10],\n                      [100, 80, 70, 60, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10],\n                      [90, 80, 70, 60, 50, 50, 40, 30, 30, 20, 20, 20, 20, 10, 10, 10],\n                      [90, 80, 70, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10, 10],\n                      [90, 80, 70, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10, 10],\n                      [80, 70, 60, 50, 50, 40, 30, 30, 20, 20, 20, 10, 10, 10, 10, 10],\n                      ])\n    PIG_1 = np.array([[100, 90, 80, 70, 60, 50, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10],\n                      [100, 90, 80, 70, 60, 50, 50, 40, 30, 30, 30, 20, 20, 20, 10, 10],\n                      [100, 90, 80, 70, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10],\n                      [100, 80, 70, 60, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10],\n                      [90, 80, 700, 60, 50, 50, 40, 30, 30, 30, 20, 20, 20, 10, 10, 10],\n                      [90, 80, 70, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10, 10],\n                      [90, 80, 70, 60, 50, 40, 40, 30, 30, 20, 20, 20, 10, 10, 10, 10],\n                      [90, 80, 60, 50, 50, 40, 30, 30, 30, 20, 20, 20, 10, 10, 10, 10],\n                      [80, 80, 60, 50, 50, 40, 30, 30, 20, 20, 20, 10, 10, 10, 10, 10]\n                      ])\n    PIG = np.stack([PIG_0, PIG_1], axis=2)\n    out = PIG[i, j, z]\n    return (out)\n\n\ndef ignition_probability(file, output, month_number):\n    \"\"\"\n    Compute ignition probability\n    :param file: layer file\n    :param output: output path\n    :param month_number: Month number\n    :return:\n    \"\"\"\n\n    print(file)\n    in_ds = ogr.Open(file)\n    in_layer = in_ds.GetLayer()\n\n    list_dictionaries = []\n    for feat in in_layer:\n\n        diccionario = {}\n\n        geom = feat.GetGeometryRef().ExportToWkt()\n\n        nfields = feat.GetFieldCount()\n        for n in range(nfields):\n            field_name = feat.GetFieldDefnRef(n).GetName()\n            if field_name == \"T_mean\": temperatura = feat.GetField(n)\n            if field_name == \"reH_mean\": reH = feat.GetField(n)\n            if field_name == \"fuel_type\":\n                value = feat.GetField(n)\n                if value in [8, 9]:\n                    shading = 1\n                else:\n                    shading = 0\n\n            if field_name == \"slope_mean\":\n                slope = feat.GetField(n)\n                if slope is None:\n                    # This has to be improved!\n                    slope = 0\n            if field_name == \"aspect_mean\": aspect = feat.GetField(n)\n\n        tmp_rfm = rfm(temperatura, reH)\n        tmp_dfm = dfm_corrections(slope, aspect, shading, month_number)\n        fdmp = tmp_rfm + tmp_dfm\n        ignition = pig(temperatura, fdmp, shading)\n        if value == 0.0: ignition = 0\n\n        diccionario[\"pig\"] = int(ignition)\n        list_dictionaries.append([geom, [diccionario]])\n\n    in_ds = None\n\n    # print(list_dictionaries)\n    create_layer(output, list_dictionaries, driver_name = \"GPKG\", data_type = ogr.OFTInteger)\n\n\ndef ignition_probability_toFolders(folderin, folderout, month_number):\n    \"\"\"\n    Apply ignition probability to folders\n    :param folderin:\n    :param folderout:\n    :param month_number:\n    :return:\n    \"\"\"\n    def getouts(a):\n        b = a.split(\"/\")\n        b = b[len(b) - 1]\n        name, coordinates, tilegpkg = b.split(\"_\")\n        out = f\"pig_{coordinates}_{tilegpkg}\"\n        return (out)\n\n    listins = list(map(lambda x: f\"{folderin}/{x}\", os.listdir(folderin)))\n    listouts = list(map(lambda x: f\"{folderout}/{getouts(x)}\", listins))\n    ooout = list(map(lambda x, y, z: ignition_probability(x, y, z), listins, listouts, [month_number] * len(listouts)))\n    return (ooout)\n\n\ndef fireRisk(in_to, in_from, output, buffer_distance=20000.0):\n    \"\"\"\n    Compute fire risk\n    :param in_to: Probability ignition layer\n    :param in_from: Auxiliary data layer\n    :param output: output\n    :param buffer_distance: By default 20000.0\n    :return:\n    \"\"\"\n    pig_ds = ogr.Open(in_to)\n    leisure_ds = ogr.Open(in_from)\n    pig_layer = pig_ds.GetLayer()\n    leisure_layer = leisure_ds.GetLayer()\n\n    trigger = 0\n    lista_features = []\n    ultra_diccionario = {}\n    for leisure_feat in leisure_layer:\n        leisure_geom = leisure_feat.GetGeometryRef()\n\n        for pig_feat in pig_layer:\n            diccionario = {}\n            #         print(diccionario)\n            pig_geom = pig_feat.GetGeometryRef()\n            pig_geomWkt = pig_geom.ExportToWkt()\n\n            nfields = pig_feat.GetFieldCount()\n            for i in range(nfields):\n                field_name = pig_feat.GetFieldDefnRef(i).GetName()\n                field_value = pig_feat.GetField(i)\n                if field_name == \"pig\":\n                    pig = field_value\n\n                diccionario[field_name] = field_value\n\n            if pig_geomWkt in ultra_diccionario:\n                if \"fireRisk\" in ultra_diccionario[pig_geomWkt][0]:\n                    trigger = 1\n                    old_value = float(ultra_diccionario[pig_geomWkt][0][\"fireRisk\"])\n\n            if leisure_geom.Intersects(pig_geom.Centroid().Buffer(buffer_distance)):\n                if leisure_geom.Contains(pig_geom.Centroid()):\n                    distancia = 0.0\n                else:\n                    distancia = float(leisure_geom.Distance(pig_geom.Centroid()))\n\n            else:\n\n                distancia = buffer_distance\n\n            fireRisk = ((buffer_distance - distancia) / buffer_distance) * pig\n            #             print(distancia, pig, fireRisk)\n            if trigger == 1:\n                if old_value > fireRisk:\n                    fireRisk = old_value\n                trigger = 0\n\n            diccionario[\"fireRisk\"] = fireRisk\n            #         print(old_value, distancia, trigger, old_value < distancia)\n            del distancia\n\n            ultra_diccionario[pig_geomWkt] = [diccionario]\n\n    leisure_ds = None\n    pig_ds = None\n\n    for k, v in ultra_diccionario.items():\n        lista_features.append([k, v])\n\n    create_layer(output, lista_features)\n\n\ndef fire_risk_toFolders(folderin, folderout, auxiliary_layer, buffer_distance = 20000.0):\n    \"\"\"\n    Compute fire risk to folders\n    :param folderin:\n    :param folderout:\n    :param auxiliary_layer:\n    :param buffer_distance:\n    :return:\n    \"\"\"\n\n    def getouts(a):\n        b = a.split(\"/\")\n        b = b[len(b) - 1]\n        name, coordinates, tilegpkg = b.split(\"_\")\n        out = f\"fireRisk_{coordinates}_{tilegpkg}\"\n        return (out)\n\n    listins = list(map(lambda x: f\"{folderin}/{x}\", os.listdir(folderin)))\n    listouts = list(map(lambda x: f\"{folderout}/{getouts(x)}\", listins))\n    ooout = list(map(lambda x, y, z, a: fireRisk(x, z, y, a),\n                     listins,\n                     listouts,\n                     [auxiliary_layer] * len(listouts),\n                     [buffer_distance] * len(listouts)\n                    ))\n    return (ooout)\n\n\nif __name__==\"__main__\":\n    create_grid_from_name(\"tmp/test/tiles\", spacing = 250, intile_length = 2000)\n\n    # layer = \"input/caba_limites.gpkg\"\n    # createGrid(path_to_layer = layer, spacing=500, epsg=25830, output = \"tmp/layers/caba_500m_tiles.gpkg\")\n\n    # imagen = \"tmp/images_test/S2A_MSIL1C_20180427T110621_N0206_R137_T30SUJ_20180427T133034/A014863/T30SUJ_20180427T110621_B04.jp2\"\n    # a = reproject(image = imagen, output_folder = \"tmp/reprojected_images\", epsg_to=25830)\n", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}