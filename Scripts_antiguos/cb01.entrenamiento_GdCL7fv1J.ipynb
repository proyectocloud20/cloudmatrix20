{"cells": [{"metadata": {}, "cell_type": "code", "source": "from time import time\nstart_time = time()", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport pywren_ibm_cloud as pywren\n", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='11007eab-26fb-471c-a850-4f2bd4c721ca', project_access_token='p-f6bd793f68c5ad2805a05d46074d9077e76be212')\npc = project.project_context\n", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## CB01.ENTRENAMIENTO.py"}, {"metadata": {}, "cell_type": "code", "source": "\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_007c356678ae40188e2c58411b04f488 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='iHDdDIdO7M6NYJzQj4aDdD1emj2oKC1R-4SocY6sGCnZ',\n    ibm_auth_endpoint=\"https://iam.eu-gb.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_007c356678ae40188e2c58411b04f488.get_object(Bucket='montecarlo-donotdelete-pr-npk3qzjotb017k', Key='classify.gpkg')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n\n", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from geopandas import read_file,GeoDataFrame\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier # este algoritmo es el que ofreci mejores resultados en las pruebas\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nsc = SparkContext.getOrCreate()\nspark = SQLContext(sc)\n\n", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "datosEntrenamiento=read_file(streaming_body_1)", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfEntrenamiento=spark.createDataFrame(datosEntrenamiento)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_2 = client_007c356678ae40188e2c58411b04f488.get_object(Bucket='montecarlo-donotdelete-pr-npk3qzjotb017k', Key='segmented_TopFixed.gpkg')['Body']\n# add missing __iter__ method so pandas accepts body as file-like object\nif not hasattr(streaming_body_2, \"__iter__\"): streaming_body_2.__iter__ = types.MethodType( __iter__, streaming_body_2 ) \n", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "datosGlobales=read_file(streaming_body_2)", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfGlobal=spark.createDataFrame(datosGlobales)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfE=dfEntrenamiento.select(\"cat\",\"tipo\").join(dfGlobal,\"cat\",\"inner\")", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "columnas=['area', 'perimeter',  'fd', 'perimeter', 'compact_circle', 'fd', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\nconstructor=VectorAssembler(inputCols=columnas,outputCol=\"features\")\n", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfEF=constructor.transform(dfE).select(\"cat\",\"features\",\"tipo\")", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "entrena,evalua=dfEF.randomSplit([0.8,0.2])", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "rf=RandomForestClassifier(labelCol=\"tipo\")", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "modelo=rf.fit(entrena)", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred=modelo.transform(evalua)", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "evaluador=MulticlassClassificationEvaluator(labelCol=\"tipo\",metricName=\"accuracy\")", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "evaluador.evaluate(pred)", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "0.8157894736842105"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "modeloOk = rf.fit(dfEF)", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "modeloOk.write().overwrite().save('modeloRF')", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#project.save_data(data = modeloOk, file_name = 'modeloRf', overwrite = True) ", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "os.getcwd()", "execution_count": 25, "outputs": [{"output_type": "execute_result", "execution_count": 25, "data": {"text/plain": "'/home/dsxuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "os.listdir()", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "['modeloRF']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.classification import RandomForestClassificationModel\nimport pandas as pd", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## CB02.PREDICCION.py"}, {"metadata": {}, "cell_type": "code", "source": "dfEF2=constructor.transform(dfGlobal).select(\"cat\",\"features\")", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "modelo=RandomForestClassificationModel().read().load(\"modeloRF\")", "execution_count": 29, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred=modelo.transform(dfEF2).select(\"cat\",\"prediction\")", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predPandas=pd.merge(datosGlobales, pred.toPandas(), on='cat', how='inner')", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "geoPredPandas=GeoDataFrame(predPandas)", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "geoPredPandas.to_file(\"prediccion.gpkg\",driver=\"GPKG\")", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## CB02.VALIDACION.py"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import ShuffleSplit,cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np ", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df=datosEntrenamiento[[\"cat\",\"tipo\"]].merge(datosGlobales,on=\"cat\",how=\"left\").dropna()", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "columnasVal=['area', 'perimeter',  'fd', 'compact_circle', 'B1_sum', 'B1_mean', 'B1_median', 'B1_stdev', 'B1_min', 'B1_max', 'B1_variance', 'B2_sum', 'B2_mean', 'B2_median', 'B2_stdev', 'B2_min', 'B2_max', 'B2_variance', 'B3_sum', 'B3_mean', 'B3_median', 'B3_stdev', 'B3_min', 'B3_max', 'B3_variance']\n\n", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y=np.array(df['tipo'])\nX=np.array(df[columnas])\n", "execution_count": 37, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "clasificador=RandomForestClassifier(n_estimators=30)", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cv = ShuffleSplit(n_splits=10,test_size=0.2,random_state=0)", "execution_count": 40, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "evaluacion=cross_val_score(clasificador,X,y,cv=cv)", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"EN %d PREDICCIONES\\nACIERTO media:  %0.2f, desviaci\u00f3n t\u00edpica: %0.2f\" % (cv.n_splits,evaluacion.mean(),evaluacion.std()*2))", "execution_count": 42, "outputs": [{"output_type": "stream", "text": "EN 10 PREDICCIONES\nACIERTO media:  0.79, desviaci\u00f3n t\u00edpica: 0.08\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "elapsed = time()\nprint(\"\\nCompleted in: \" + str(elapsed - start_time) + \" seconds\")", "execution_count": 43, "outputs": [{"output_type": "stream", "text": "\nCompleted in: 327.51116609573364 seconds\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(os.stat(\"prediccion.gpkg\").st_size/1024/1024)", "execution_count": 44, "outputs": [{"output_type": "stream", "text": "163.15234375\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client_007c356678ae40188e2c58411b04f488.upload_file('prediccion.gpkg','montecarlo-donotdelete-pr-npk3qzjotb017k','prediccion.gpkg',ExtraArgs={'Metadata': {'mykey': 'iHDdDIdO7M6NYJzQj4aDdD1emj2oKC1R-4SocY6sGCnZ'}})\n", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}